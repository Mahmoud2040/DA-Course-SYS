Algorithm complexity is used to measure how the runtime or resource usage grows with input size. Common complexities include:

## O(1) – Constant time:
The operation always takes the same amount of time, regardless of input size.
Example: Accessing an element in an array by index.

## O(log n) – Logarithmic time:
The runtime grows slowly as input size increases, usually by dividing the problem in half each step.
Example: Binary search in a sorted list.

## O(n) – Linear time:
The runtime increases directly in proportion to the input size.
Example: Scanning through all elements in a list.

## O(n log n) – Linearithmic time:
Slightly slower than linear, common in efficient divide-and-conquer algorithms.
Example: Merge sort, quicksort (average case).

## O(n²) – Quadratic time:
Runtime grows with the square of the input size, often from nested loops.
Example: Checking all pairs in a list.

## O(2ⁿ) – Exponential time:
Runtime doubles with each additional input element, extremely inefficient for large inputs.
Example: Brute-force solutions for combinatorial problems.